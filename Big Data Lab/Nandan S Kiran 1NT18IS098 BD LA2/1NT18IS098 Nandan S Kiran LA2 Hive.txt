hdoop@nandan-Aspire-E5-571P:~$ start-all.sh
WARNING: Attempting to start all Apache Hadoop daemons as hdoop in 10 seconds.
WARNING: This is not a recommended production deployment configuration.
WARNING: Use CTRL-C to abort.
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [nandan-Aspire-E5-571P]
Starting resourcemanager
Starting nodemanagers
hdoop@nandan-Aspire-E5-571P:~$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hdoop/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = a572a40d-6086-46e6-bb45-17c72301370b

Logging initialized using configuration in jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 752caf11-30ef-4bea-b3fb-7fe0b435bfcd
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> show databases;
OK
bank
customer
default
employeedb
nandan
Time taken: 0.865 seconds, Fetched: 5 row(s)
hive> use employeedb;
OK
Time taken: 0.03 seconds
hive> desc employee;
FAILED: SemanticException [Error 10001]: Table not found employee
hive> desc emp;
OK
name                	string              	                    
ssn                 	int                 	                    
salary              	float               	                    
address             	string              	                    
dept_name           	string              	                    
experience          	int                 	                    
Time taken: 0.643 seconds, Fetched: 6 row(s)
hive> select * from employee;
FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'employee'
hive> select * from emp;
OK
Akhila	5020	63000.0	Bangalore	ISE	3
Sunny	5021	70000.0	Mysore	CSE	4
Sthuthi	5022	71000.0	Shimoga	ISE	5
Arnav	5023	72000.0	Hornadu	ME	4
Naveen	5024	73000.0	Mangalore	ISE	8
Harsha	5000	30000.0	Bangalore	ISE	5
Adarsh	5001	35000.0	Sirsi	ISE	6
Nandan	5002	36000.0	Bangalore	ISE	6
Raghav	5003	40000.0	Hassan	CSE	6
Dharni	5004	41000.0	Chennai	ECE	6
Aniket	5005	45000.0	Hyderabad	ME	6
Darshan	5006	46000.0	Honnavar	ISE	5
Asha	5007	47000.0	Puttur	ISE	5
Harshith	5008	20000.0	Tumkur	ECE	7
Divine	5009	80000.0	Udupi	ISE	5
Aditya	5010	50000.0	Bhadra	ISE	6
Ashok	5011	24000.0	Bangalore	ISE	5
Sujan	5012	25000.0	Mangalore	CSE	5
Sanket	5013	26000.0	Mangalore	CSE	6
Bharat	5014	27000.0	Gurgaon	ISE	7
Abhay	5015	28000.0	Mumbai	ISE	5
Sandeep	5016	30000.0	Shimoga	CSE	7
Alok	5017	60000.0	Bihar	ISE	5
Navami	5018	61000.0	Bangalore	ISE	5
Anjali	5019	64000.0	Delhi	ISE	5
Time taken: 2.785 seconds, Fetched: 25 row(s)
hive> alter table emp rename to empl;
OK
Time taken: 0.42 seconds
hive> alter table empl rename to emp;
OK
Time taken: 0.213 seconds
hive> desc emp;
OK
name                	string              	                    
ssn                 	int                 	                    
salary              	float               	                    
address             	string              	                    
dept_name           	string              	                    
experience          	int                 	                    
Time taken: 0.063 seconds, Fetched: 6 row(s)
hive>  alter table Emp change  dept_name dname string;
OK
Time taken: 0.451 seconds
hive>  alter table Emp change  dname dept_name string;
OK
Time taken: 0.212 seconds
hive> desc emp;
OK
name                	string              	                    
ssn                 	int                 	                    
salary              	float               	                    
address             	string              	                    
dept_name           	string              	                    
experience          	int                 	                    
Time taken: 0.056 seconds, Fetched: 6 row(s)
hive> select Name,SSN,Salary from emp where Salary>=50000;
OK
Akhila	5020	63000.0
Sunny	5021	70000.0
Sthuthi	5022	71000.0
Arnav	5023	72000.0
Naveen	5024	73000.0
Divine	5009	80000.0
Aditya	5010	50000.0
Alok	5017	60000.0
Navami	5018	61000.0
Anjali	5019	64000.0
Time taken: 0.57 seconds, Fetched: 10 row(s)
hive> select Name,address,experience from emp where address="Bangalore" and experience<5;
OK
Akhila	Bangalore	3
Time taken: 0.337 seconds, Fetched: 1 row(s)
hive> create view namedept as select Name,Deptname from emp;
FAILED: SemanticException [Error 10004]: Line 1:36 Invalid table alias or column reference 'Deptname': (possible column names are: name, ssn, salary, address, dept_name, experience)
hive> create view namedept1 as select Name,Deptname from emp;
FAILED: SemanticException [Error 10004]: Line 1:37 Invalid table alias or column reference 'Deptname': (possible column names are: name, ssn, salary, address, dept_name, experience)
hive> create view namedept1 as select name,dept_name from emp;
OK
Time taken: 0.396 seconds
hive> select * from namedept1;
OK
Akhila	ISE
Sunny	CSE
Sthuthi	ISE
Arnav	ME
Naveen	ISE
Harsha	ISE
Adarsh	ISE
Nandan	ISE
Raghav	CSE
Dharni	ECE
Aniket	ME
Darshan	ISE
Asha	ISE
Harshith	ECE
Divine	ISE
Aditya	ISE
Ashok	ISE
Sujan	CSE
Sanket	CSE
Bharat	ISE
Abhay	ISE
Sandeep	CSE
Alok	ISE
Navami	ISE
Anjali	ISE
Time taken: 0.283 seconds, Fetched: 25 row(s)
hive> desc namedept1;
OK
name                	string              	                    
dept_name           	string              	                    
Time taken: 0.054 seconds, Fetched: 2 row(s)
hive> select name,ssn from emp group by name,ssn order by name;
Query ID = hdoop_20210703221957_c227f9a7-792a-4e0f-94a2-7d58db36ade6
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625330327852_0001, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0001/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-03 22:20:24,277 Stage-1 map = 0%,  reduce = 0%
2021-07-03 22:20:47,799 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.95 sec
2021-07-03 22:21:16,845 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec
MapReduce Total cumulative CPU time: 5 seconds 550 msec
Ended Job = job_1625330327852_0001
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625330327852_0002, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0002/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0002
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2021-07-03 22:21:34,288 Stage-2 map = 0%,  reduce = 0%
2021-07-03 22:21:55,693 Stage-2 map = 67%,  reduce = 0%, Cumulative CPU 4.95 sec
2021-07-03 22:21:58,499 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.12 sec
2021-07-03 22:22:28,706 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.85 sec
MapReduce Total cumulative CPU time: 7 seconds 850 msec
Ended Job = job_1625330327852_0002
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 12757 HDFS Write: 767 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.85 sec   HDFS Read: 8177 HDFS Write: 683 SUCCESS
Total MapReduce CPU Time Spent: 13 seconds 400 msec
OK
Abhay	5015
Adarsh	5001
Aditya	5010
Akhila	5020
Alok	5017
Aniket	5005
Anjali	5019
Arnav	5023
Asha	5007
Ashok	5011
Bharat	5014
Darshan	5006
Dharni	5004
Divine	5009
Harsha	5000
Harshith	5008
Nandan	5002
Navami	5018
Naveen	5024
Raghav	5003
Sandeep	5016
Sanket	5013
Sthuthi	5022
Sujan	5012
Sunny	5021
Time taken: 154.35 seconds, Fetched: 25 row(s)
hive> select max(salary),min(salary),avg(salary) from emp;
Query ID = hdoop_20210703222248_6b8ab696-2ac7-49e1-a9ca-63826745b62d
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625330327852_0003, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0003/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-03 22:23:00,984 Stage-1 map = 0%,  reduce = 0%
2021-07-03 22:23:22,752 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.73 sec
2021-07-03 22:23:42,280 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.36 sec
MapReduce Total cumulative CPU time: 6 seconds 360 msec
Ended Job = job_1625330327852_0003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.36 sec   HDFS Read: 18170 HDFS Write: 123 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 360 msec
OK
80000.0	20000.0	46560.0
Time taken: 57.333 seconds, Fetched: 1 row(s)
hive> desc department;
OK
dno                 	int                 	                    
dept_name           	string              	                    
Time taken: 0.166 seconds, Fetched: 2 row(s)
hive> select * from department;
OK
6	ISE
1	CSE
2	ECE
3	ME
Time taken: 0.239 seconds, Fetched: 4 row(s)
hive> insert into department values(7,"EEE");
Query ID = hdoop_20210703222505_4faf0e1d-cfd3-4997-8c43-21b0e48c54df
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625330327852_0004, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0004/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-03 22:25:21,855 Stage-1 map = 0%,  reduce = 0%
2021-07-03 22:25:44,890 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.66 sec
2021-07-03 22:26:09,894 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 9.53 sec
MapReduce Total cumulative CPU time: 9 seconds 530 msec
Ended Job = job_1625330327852_0004
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://127.0.0.1:9000/user/hive/warehouse/employeedb.db/department/.hive-staging_hive_2021-07-03_22-25-05_832_6296653711727226259-1/-ext-10000
Loading data to table employeedb.department
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 9.53 sec   HDFS Read: 15637 HDFS Write: 246 SUCCESS
Total MapReduce CPU Time Spent: 9 seconds 530 msec
OK
Time taken: 68.291 seconds
hive> select * from department;
OK
6	ISE
1	CSE
2	ECE
3	ME
7	EEE
Time taken: 0.172 seconds, Fetched: 5 row(s)
hive>  select name,ssn,d.dept_name,dno from emp e full outer join department d on e.dept_name=d.dept_name;
Query ID = hdoop_20210703222700_5aa2a97c-b0cc-4113-9003-2951429d7ca0
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625330327852_0005, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0005/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0005
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
2021-07-03 22:27:13,859 Stage-1 map = 0%,  reduce = 0%
2021-07-03 22:28:16,627 Stage-1 map = 0%,  reduce = 0%
2021-07-03 22:28:45,753 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 136.88 sec
2021-07-03 22:29:12,318 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 137.27 sec
2021-07-03 22:30:12,989 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 137.27 sec
2021-07-03 22:30:39,624 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 139.91 sec
MapReduce Total cumulative CPU time: 2 minutes 19 seconds 910 msec
Ended Job = job_1625330327852_0005
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 139.91 sec   HDFS Read: 17935 HDFS Write: 855 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 19 seconds 910 msec
OK
Sunny	5021	CSE	1
Raghav	5003	CSE	1
Sujan	5012	CSE	1
Sandeep	5016	CSE	1
Sanket	5013	CSE	1
Dharni	5004	ECE	2
Harshith	5008	ECE	2
NULL	NULL	EEE	7
Anjali	5019	ISE	6
Navami	5018	ISE	6
Alok	5017	ISE	6
Abhay	5015	ISE	6
Bharat	5014	ISE	6
Ashok	5011	ISE	6
Aditya	5010	ISE	6
Divine	5009	ISE	6
Asha	5007	ISE	6
Darshan	5006	ISE	6
Nandan	5002	ISE	6
Adarsh	5001	ISE	6
Harsha	5000	ISE	6
Naveen	5024	ISE	6
Sthuthi	5022	ISE	6
Akhila	5020	ISE	6
Arnav	5023	ME	3
Aniket	5005	ME	3
Time taken: 223.572 seconds, Fetched: 26 row(s)
hive> select name,ssn,d.dept_name,dno from emp e left outer join department d on e.dept_name=d.dept_name;
Query ID = hdoop_20210703223401_16902440-f94a-43fc-a329-e3adc736b479
Total jobs = 1


SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
2021-07-03 22:34:16	Starting to launch local task to process map join;	maximum memory = 239075328

Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1625330327852_0006, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0006/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0006
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2021-07-03 22:34:33,310 Stage-3 map = 0%,  reduce = 0%
2021-07-03 22:34:40,745 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.5 sec
MapReduce Total cumulative CPU time: 3 seconds 500 msec
Ended Job = job_1625330327852_0006
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 3.5 sec   HDFS Read: 10262 HDFS Write: 831 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 500 msec
OK
Akhila	5020	ISE	6
Sunny	5021	CSE	1
Sthuthi	5022	ISE	6
Arnav	5023	ME	3
Naveen	5024	ISE	6
Harsha	5000	ISE	6
Adarsh	5001	ISE	6
Nandan	5002	ISE	6
Raghav	5003	CSE	1
Dharni	5004	ECE	2
Aniket	5005	ME	3
Darshan	5006	ISE	6
Asha	5007	ISE	6
Harshith	5008	ECE	2
Divine	5009	ISE	6
Aditya	5010	ISE	6
Ashok	5011	ISE	6
Sujan	5012	CSE	1
Sanket	5013	CSE	1
Bharat	5014	ISE	6
Abhay	5015	ISE	6
Sandeep	5016	CSE	1
Alok	5017	ISE	6
Navami	5018	ISE	6
Anjali	5019	ISE	6
Time taken: 42.247 seconds, Fetched: 25 row(s)
hive> select name,ssn,d.dept_name,dno from emp e right outer join department d on e.dept_name=d.dept_name;
Query ID = hdoop_20210703223531_0fd902d3-584d-4b5d-a4e4-5ceefd5975b1
Total jobs = 1


SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1625330327852_0007, Tracking URL = http://nandan-Aspire-E5-571P:8088/proxy/application_1625330327852_0007/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625330327852_0007
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2021-07-03 22:35:59,014 Stage-3 map = 0%,  reduce = 0%
2021-07-03 22:36:06,229 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.45 sec
MapReduce Total cumulative CPU time: 3 seconds 450 msec
Ended Job = job_1625330327852_0007
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 3.45 sec   HDFS Read: 8978 HDFS Write: 855 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 450 msec
OK
Akhila	5020	ISE	6
Sthuthi	5022	ISE	6
Naveen	5024	ISE	6
Harsha	5000	ISE	6
Adarsh	5001	ISE	6
Nandan	5002	ISE	6
Darshan	5006	ISE	6
Asha	5007	ISE	6
Divine	5009	ISE	6
Aditya	5010	ISE	6
Ashok	5011	ISE	6
Bharat	5014	ISE	6
Abhay	5015	ISE	6
Alok	5017	ISE	6
Navami	5018	ISE	6
Anjali	5019	ISE	6
Sunny	5021	CSE	1
Raghav	5003	CSE	1
Sujan	5012	CSE	1
Sanket	5013	CSE	1
Sandeep	5016	CSE	1
Dharni	5004	ECE	2
Harshith	5008	ECE	2
Arnav	5023	ME	3
Aniket	5005	ME	3
NULL	NULL	EEE	7
Time taken: 37.508 seconds, Fetched: 26 row(s)
hive> 

